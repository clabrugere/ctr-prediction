{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "from tensorflow.python.data import Dataset, AUTOTUNE\n",
    "\n",
    "\n",
    "def train_test_split(df, train_frac, seed=42):\n",
    "    df = df.with_columns(pl.all().shuffle(seed)).with_row_count()\n",
    "    df_train = df.filter(pl.col(\"row_nr\") < pl.col(\"row_nr\").max() * train_frac).drop(\"row_nr\")\n",
    "    df_test = df.filter(pl.col(\"row_nr\") >= pl.col(\"row_nr\").max() * train_frac).drop(\"row_nr\")\n",
    "    \n",
    "    return df_train, df_test\n",
    "\n",
    "\n",
    "def to_dataset(df, batch_size, shuffle=True, buffer_size=10_000):\n",
    "    inputs, labels = df.select(pl.all().exclude(\"label\")), df.select(pl.col(\"label\"))\n",
    "    ds = Dataset.from_tensor_slices((inputs, labels)).cache()\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size)\n",
    "    ds = ds.batch(batch_size).prefetch(AUTOTUNE)\n",
    "    \n",
    "    return ds\n",
    "\n",
    "\n",
    "def prepare_data(filename, batch_size):\n",
    "    df = pl.scan_csv(filename, separator=\"\\t\").select(pl.col(\"^cat\\d+$\"), pl.col(\"click\").alias(\"label\")).collect()\n",
    "    \n",
    "    num_embeddings = len(np.unique(df.select(pl.all().exclude(\"label\")).to_numpy())) + 1\n",
    "    \n",
    "    df_train, df_test = train_test_split(df, train_frac=0.9)\n",
    "    df_train, df_val = train_test_split(df_train, train_frac=0.98)\n",
    "    \n",
    "    ds_train = to_dataset(df_train, batch_size)\n",
    "    ds_val = to_dataset(df_val, batch_size, shuffle=False)\n",
    "    ds_test = to_dataset(df_test, batch_size, shuffle=False)\n",
    "\n",
    "    return ds_train, ds_val, ds_test, num_embeddings\n",
    "\n",
    "\n",
    "filename = \"../data/criteo_attribution_dataset.tsv\"\n",
    "batch_size = 2**14\n",
    "ds_train, ds_val, ds_test, num_embeddings = prepare_data(filename, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "class EpochTimer(tf.keras.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self._reset()\n",
    "\n",
    "    def _reset(self):\n",
    "        self._step_durations = []\n",
    "        self.step_durations = []\n",
    "        self.epoch_durations = []\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self._reset()\n",
    "\n",
    "    def on_batch_begin(self, batch, logs=None):\n",
    "        self._step_start_timestamp = timer()\n",
    "\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        self._step_durations.append(timer() - self._step_start_timestamp)\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self._epoch_start_timestamp = timer()\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.step_durations.append(np.mean(self._step_durations))\n",
    "        self._step_durations = []\n",
    "        self.epoch_durations.append(timer() - self._epoch_start_timestamp)\n",
    "\n",
    "\n",
    "def train(\n",
    "    model,\n",
    "    ds_train,\n",
    "    ds_val,\n",
    "    lr,\n",
    "    epochs,\n",
    "    verbose=1,\n",
    "):\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=lr)\n",
    "    model.compile(optimizer=optimizer, loss=\"binary_crossentropy\")\n",
    "    timer_callback = EpochTimer()\n",
    "    callbacks = [\n",
    "        timer_callback,\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", patience=2, mode=\"min\", verbose=1),\n",
    "        tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=3, verbose=1),\n",
    "    ]\n",
    "    history = model.fit(\n",
    "        ds_train,\n",
    "        validation_data=ds_val,\n",
    "        epochs=epochs,\n",
    "        callbacks=callbacks,\n",
    "        verbose=verbose,\n",
    "    )\n",
    "    hist_dict = history.history\n",
    "    hist_dict[\"epoch_duration\"] = timer_callback.epoch_durations\n",
    "    hist_dict[\"step_duration\"] = timer_callback.step_durations\n",
    "\n",
    "    return hist_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "887/887 [==============================] - 25s 26ms/step - loss: 0.6548 - val_loss: 0.6538 - lr: 0.1000\n",
      "Epoch 2/10\n",
      "887/887 [==============================] - 23s 25ms/step - loss: 0.6542 - val_loss: 0.6538 - lr: 0.1000\n",
      "Epoch 3/10\n",
      "887/887 [==============================] - ETA: 0s - loss: 0.6542\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.010000000149011612.\n",
      "887/887 [==============================] - 23s 25ms/step - loss: 0.6542 - val_loss: 0.6537 - lr: 0.1000\n",
      "Epoch 4/10\n",
      "887/887 [==============================] - 23s 25ms/step - loss: 0.6541 - val_loss: 0.6538 - lr: 0.0100\n",
      "Epoch 5/10\n",
      "885/887 [============================>.] - ETA: 0s - loss: 0.6541\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "887/887 [==============================] - 23s 25ms/step - loss: 0.6541 - val_loss: 0.6538 - lr: 0.0100\n",
      "Epoch 6/10\n",
      "887/887 [==============================] - 23s 25ms/step - loss: 0.6541 - val_loss: 0.6537 - lr: 1.0000e-03\n",
      "Epoch 7/10\n",
      "885/887 [============================>.] - ETA: 0s - loss: 0.6541\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "887/887 [==============================] - 23s 25ms/step - loss: 0.6541 - val_loss: 0.6537 - lr: 1.0000e-03\n",
      "Epoch 8/10\n",
      "887/887 [==============================] - 23s 25ms/step - loss: 0.6541 - val_loss: 0.6537 - lr: 1.0000e-04\n",
      "Epoch 9/10\n",
      "885/887 [============================>.] - ETA: 0s - loss: 0.6541\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
      "887/887 [==============================] - 23s 24ms/step - loss: 0.6541 - val_loss: 0.6537 - lr: 1.0000e-04\n",
      "Epoch 9: early stopping\n"
     ]
    }
   ],
   "source": [
    "from models.tensorflow.gdcn import GDCNS\n",
    "\n",
    "gcdn_model = GDCNS(\n",
    "    dim_input=ds_train.element_spec[0].shape[1],\n",
    "    num_embedding=num_embeddings,\n",
    "    dim_embedding=8,\n",
    "    num_cross=3,\n",
    "    num_hidden=3,\n",
    "    dim_hidden=128,\n",
    ")\n",
    "\n",
    "hist = train(gcdn_model, ds_train, ds_val, lr=1e-1, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101/101 [==============================] - 2s 20ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = gcdn_model.predict(ds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ctr-prediction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
